{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1db53d",
   "metadata": {
    "id": "fd1db53d"
   },
   "source": [
    "## **NLP - Text Classification Project**\n",
    "Group H - August 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39c64d",
   "metadata": {
    "id": "0e39c64d"
   },
   "source": [
    "Classification of tweets from Twitter that have been manually tagged for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "MdWj5rFhiNYR",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1753564669573,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "MdWj5rFhiNYR"
   },
   "outputs": [],
   "source": [
    "# # Needed for Google Colab\n",
    "# !pip install --quiet evaluate transformers optuna datasets nltk scikit-learn\n",
    "# !pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01b425b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1753564670945,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "01b425b0",
    "outputId": "f03c2605-b672-4002-e549-ea8a0b9e00bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from optuna.pruners import MedianPruner\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import glob\n",
    "import nltk\n",
    "import evaluate\n",
    "import transformers\n",
    "import optuna\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"tweet-sentiment-classification\"\n",
    "os.environ[\"WANDB_INIT_TIMEOUT\"] = \"180\"\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "862fa5f6",
   "metadata": {
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1753564671114,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "862fa5f6"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp_project/Data/Corona_NLP_train.csv', encoding='latin1')\n",
    "df_val = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp_project/Data/Corona_NLP_test.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa38e28",
   "metadata": {
    "id": "bfa38e28"
   },
   "source": [
    "### Pre-processing the Data\n",
    "\n",
    "The tweets were cleaned by lowercasing (to reduce redundancy), removing stopwords, punctuation, numbers, short words, and applying lemmatization to reduce words to their base form (e.g. running → run). <br>This helps reduce noise and improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab93defa",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753564671125,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "ab93defa"
   },
   "outputs": [],
   "source": [
    "# # Try agressive pre-processing\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     text = str(text).lower()\n",
    "#     text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)              # Remove URLs\n",
    "#     text = re.sub(r\"[^a-z\\s]\", \"\", text)                     # Remove punctuation & numbers\n",
    "#     tokens = text.split()\n",
    "#     tokens = [\n",
    "#         lemmatizer.lemmatize(word)\n",
    "#         for word in tokens\n",
    "#         if word not in stop_words\n",
    "#         and word not in domain_stopwords\n",
    "#         and len(word) > 2\n",
    "#     ]\n",
    "#     return \" \".join(tokens)\n",
    "\n",
    "# df_train[\"clean_text\"] = df_train[\"OriginalTweet\"].apply(preprocess_text)\n",
    "# df_val[\"clean_text\"] = df_val[\"OriginalTweet\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "CQFqLTPYEGMt",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753564671131,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "CQFqLTPYEGMt"
   },
   "outputs": [],
   "source": [
    "# # Try minimal pre-processing\n",
    "# def preprocess_text_for_transformers(text):\n",
    "#     return \" \".join(str(text).split())  # Normalize whitespace\n",
    "\n",
    "# df_train[\"clean_text\"] = df_train[\"OriginalTweet\"].apply(preprocess_text_for_transformers)\n",
    "# df_val[\"clean_text\"] = df_val[\"OriginalTweet\"].apply(preprocess_text_for_transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "E0CCJPvOeOUL",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1753564671156,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "E0CCJPvOeOUL"
   },
   "outputs": [],
   "source": [
    "# Try without pre-processing\n",
    "df_train[\"clean_text\"] = df_train[\"OriginalTweet\"]\n",
    "df_val[\"clean_text\"] = df_val[\"OriginalTweet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09004284",
   "metadata": {
    "id": "09004284"
   },
   "source": [
    "## Fine-Tuning Pretrained Language Models\n",
    "\n",
    "Apply NLP techniques using transfer learning on our tweets dataset. Specifically, fine-tuning two pretrained transformer-based models from the Hugging Face library — BERT and RoBERTa — on our sentiment classification task. These models will be trained using both standard PyTorch and the Hugging Face API. Model performance will be monitored and tuned using hyperparameter optimization (Optuna) and experiment tracking (Weights & Biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150169f",
   "metadata": {
    "id": "f150169f"
   },
   "source": [
    "**Load Pretrained Models**\n",
    "\n",
    "Initialize tokenizers and models for BERT and RoBERTa, both widely used transformer architectures for text classification. The classification head is configured based on the number of sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa45887",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1753564672262,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "eaa45887",
    "outputId": "b6635c1e-984b-4182-f4b0-26285f0a279a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Choose pretrained models\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "roberta_model_name = \"roberta-base\"\n",
    "\n",
    "sentiment_labels = df_train['Sentiment'].unique()\n",
    "n_labels = len(sentiment_labels)\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels=n_labels)\n",
    "\n",
    "# Load RoBERTa tokenizer and model\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_model_name, num_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f221d5",
   "metadata": {
    "id": "51f221d5"
   },
   "source": [
    "**Encode Sentiment Labels**\n",
    "\n",
    "Map each unique sentiment label to a numeric ID for model compatibility, and apply this mapping to both training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e31c36",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753564672273,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "b2e31c36"
   },
   "outputs": [],
   "source": [
    "# Mapping sentiments to unique numeric IDs\n",
    "label2id = {label: idx for idx, label in enumerate(df_train[\"Sentiment\"].unique())}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "df_train[\"label\"] = df_train[\"Sentiment\"].map(label2id)\n",
    "df_val[\"label\"] = df_val[\"Sentiment\"].map(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b74ad6",
   "metadata": {
    "id": "92b74ad6"
   },
   "source": [
    "**Tokenization**\n",
    "\n",
    "Define tokenization functions for BERT and RoBERTa to preprocess text with truncation and fixed padding.\n",
    "\n",
    "Transform training and validation DataFrames into Dataset objects compatible with Hugging Face workflows.\n",
    "\n",
    "Apply tokenization to training and validation datasets using each model's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcb7752d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753564672278,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "dcb7752d"
   },
   "outputs": [],
   "source": [
    "# Tokenize function\n",
    "def tokenize_function_bert(examples):\n",
    "    return bert_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=64)\n",
    "\n",
    "def tokenize_function_roberta(examples):\n",
    "    return roberta_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d9f44db",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1753564672287,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "7d9f44db"
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to Hugging Face Dataset\n",
    "hf_dataset_train = Dataset.from_pandas(df_train[[\"clean_text\", \"label\"]])\n",
    "hf_dataset_val = Dataset.from_pandas(df_val[[\"clean_text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46d7765e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "021b7b1cd455429f9a394a597d7bb42d",
      "a4d498336a3145b4a4aa73fa896b734f",
      "b028b21d6bad410db6cba38dd88b576c",
      "770dfb4419744e0c8b3efae0f3978d60",
      "6acee7f7eb284cc3bf62050036746569",
      "9f5350cd17b74d28ab4c3ddd1c2f5b1d",
      "8a6cc15567344e7aaaccb719a2a6fb25",
      "b4dd09b398c1462bb967c497c63adc7e",
      "f04b24c43ab245b4a33c93196ab41376",
      "93247cfcccbb4a2fbe9a74da198a4352",
      "603dc04c8c874242bf672876cdad61cd",
      "b2d101d93d3a4a088f67f817017c0df3",
      "2927695b41b4424fb007825fb2b73bca",
      "cea30c0b25d84ac49becf7e530054c1f",
      "daaff61f5e934c7a8fb66e6064dc86ff",
      "7f74de3720c74099ac30e1664d535d4f",
      "b28ff50b4dae4c6e85e4915756474036",
      "3d3a4e702ce44740a5c5429d61a04ef3",
      "bf5cd54405444d909c688c9e2c43cc02",
      "83e540139d4a4ca582bcf872a115e960",
      "b7866be1713c4ea8adc629e771d138f4",
      "304c25bb0aec412f92862d42f8f12ec2",
      "8329a7608a9b463caefe23dc4f81217a",
      "8d5256c4c6a445bc8e3b2d95fa531909",
      "d6643b7caee0485db65270f25d806788",
      "c25775059628480aacb4ceb2ff2047f0",
      "7542e0c0a355413bb1ab419c7798003e",
      "f584d74ca0ea469bbab2c004a83c8a57",
      "fa3cd39c189242558ee65a37e2460d1a",
      "a0b7181171284283b09914d3553303a0",
      "d4acadb0a1984d3181eabee9f58476ba",
      "b37059b31275449e9daf3b481386e37c",
      "ad2f1558713a49f4b458f0b6b1eb1c18",
      "22cd9c644bc4455984cffc3ea63d56fd",
      "996a47832e9449248823fc97127afce3",
      "01393d8d662e4a02bf98e663181a0253",
      "84fbe853d81944b699940e78d0f4450c",
      "92fe0a22068e4077bac789671b65ac8b",
      "7bdeb69ab6294aa8af56486aefc82429",
      "5fbe6caaa77742d78e5198366626b78f",
      "c650e17245234be7a5d3ed6ed80f616c",
      "fcbfadd83d114f52ae85cff5113fcdb8",
      "6754ab85e774417280bc6e14fa618a74",
      "37aaf2f9b1de473eb376dab3d7a9ed3e"
     ]
    },
    "executionInfo": {
     "elapsed": 6954,
     "status": "ok",
     "timestamp": 1753564679245,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "46d7765e",
    "outputId": "2e711a1e-0b6b-4aba-d0da-a6cc2331e32a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021b7b1cd455429f9a394a597d7bb42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d101d93d3a4a088f67f817017c0df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8329a7608a9b463caefe23dc4f81217a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cd9c644bc4455984cffc3ea63d56fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize for BERT\n",
    "tokenized_bert_train = hf_dataset_train.map(tokenize_function_bert, batched=True)\n",
    "tokenized_bert_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "tokenized_bert_val = hf_dataset_val.map(tokenize_function_bert, batched=True)\n",
    "tokenized_bert_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Tokenize for RoBERTa\n",
    "tokenized_roberta_train = hf_dataset_train.map(tokenize_function_roberta, batched=True)\n",
    "tokenized_roberta_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "tokenized_roberta_val = hf_dataset_val.map(tokenize_function_roberta, batched=True)\n",
    "tokenized_roberta_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56f7558c",
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1753564679303,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "56f7558c"
   },
   "outputs": [],
   "source": [
    "# # Define evaluation metric, Set up an evaluation function using accuracy as the metric to assess model performance during training.\n",
    "\n",
    "# accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=1)\n",
    "#     return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cU06d3QJVps",
   "metadata": {
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1753564680103,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "7cU06d3QJVps"
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3d806",
   "metadata": {
    "id": "2fd3d806"
   },
   "source": [
    "**Use Small Subsets for Quick Evaluation**\n",
    "\n",
    "Select shuffled samples from each training and validation dataset for both BERT and RoBERTa. This allows faster experimentation during model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21818098",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753564680124,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "21818098"
   },
   "outputs": [],
   "source": [
    "USE_SMALL_DATASET = True\n",
    "if USE_SMALL_DATASET:\n",
    "  n_samples_train = 2000\n",
    "  n_samples_val = 500\n",
    "\n",
    "  train_dataset_bert = tokenized_bert_train.shuffle(seed=42).select(range(n_samples_train))\n",
    "  val_dataset_bert = tokenized_bert_val.shuffle(seed=42).select(range(n_samples_val))\n",
    "\n",
    "  train_dataset_roberta = tokenized_roberta_train.shuffle(seed=42).select(range(n_samples_train))\n",
    "  val_dataset_roberta = tokenized_roberta_val.shuffle(seed=42).select(range(n_samples_val))\n",
    "else:\n",
    "  n_samples_train = len(tokenized_bert_train)\n",
    "  n_samples_val = len(tokenized_bert_val)\n",
    "\n",
    "  train_dataset_bert = tokenized_bert_train\n",
    "  val_dataset_bert = tokenized_bert_val\n",
    "\n",
    "  train_dataset_roberta = tokenized_roberta_train\n",
    "  val_dataset_roberta = tokenized_roberta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b7810",
   "metadata": {
    "id": "486b7810"
   },
   "source": [
    "**Define Training Arguments**\n",
    "\n",
    "Configure hyperparameters and training settings for both BERT and RoBERTa models, including batch size, number of epochs, learning rate, and evaluation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10fd9daf",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753564680134,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "10fd9daf"
   },
   "outputs": [],
   "source": [
    "# # Define hyperparameters\n",
    "# run_time = f\"run-{int(time.time())}\"\n",
    "\n",
    "# num_epochs_bert = 5\n",
    "# learning_rate_bert = 4.037872385196561e-05\n",
    "# batch_size_bert = 16\n",
    "\n",
    "# bert_training_args = TrainingArguments(\n",
    "#     output_dir=\"./results/bert/{run_time}\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=batch_size_bert,\n",
    "#     per_device_eval_batch_size=batch_size_bert,\n",
    "#     num_train_epochs=num_epochs_bert,\n",
    "#     learning_rate=learning_rate_bert,\n",
    "#     weight_decay=0.01,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_dir=\"./logs/bert/{run_time}\",\n",
    "#     run_name = f\"bert-ep{num_epochs_bert}-lr{learning_rate_bert}-bs{batch_size_bert}-samples{n_samples_train}-run{int(time.time())}-no_preprocess\",\n",
    "#     report_to=\"wandb\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf8b509c",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1753564680151,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "bf8b509c"
   },
   "outputs": [],
   "source": [
    "# # Define hyperparameters\n",
    "# num_epochs_roberta = 4\n",
    "# learning_rate_roberta = 4e-5\n",
    "# batch_size_roberta = 16\n",
    "\n",
    "# roberta_training_args = TrainingArguments(\n",
    "#     output_dir=\"./results/roberta/{run_time}\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     per_device_train_batch_size=batch_size_roberta,\n",
    "#     per_device_eval_batch_size=batch_size_roberta,\n",
    "#     num_train_epochs=num_epochs_roberta,\n",
    "#     learning_rate=learning_rate_roberta,\n",
    "#     weight_decay=0.01,\n",
    "#     load_best_model_at_end=True,\n",
    "#     logging_dir=\"./logs/roberta/{run_time}\",\n",
    "#     run_name=f\"roberta-ep{num_epochs_roberta}-lr{learning_rate_roberta}-bs{batch_size_roberta}-samples{n_samples_train}-run{int(time.time())}-no_preprocess\",\n",
    "#     report_to=\"wandb\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c66bb",
   "metadata": {
    "id": "e30c66bb"
   },
   "source": [
    "**Initialize Trainers**\n",
    "\n",
    "Configure Trainer objects for both BERT and RoBERTa using the small training and validation sets, tokenizers, training arguments, and evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7164d5b",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1753564680169,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "c7164d5b"
   },
   "outputs": [],
   "source": [
    "# bert_trainer = Trainer(\n",
    "#     model=bert_model,\n",
    "#     args=bert_training_args,\n",
    "#     train_dataset=train_dataset_bert,\n",
    "#     eval_dataset=val_dataset_bert,\n",
    "#     tokenizer=bert_tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d1be505",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753564680177,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "8d1be505"
   },
   "outputs": [],
   "source": [
    "# roberta_trainer = Trainer(\n",
    "#     model=roberta_model,\n",
    "#     args=roberta_training_args,\n",
    "#     train_dataset=train_dataset_roberta,\n",
    "#     eval_dataset=val_dataset_roberta,\n",
    "#     tokenizer=roberta_tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a08c2c",
   "metadata": {
    "id": "44a08c2c"
   },
   "source": [
    "**Model Training**\n",
    "\n",
    "Train both BERT and RoBERTa models on the small datasets using the Trainer interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B0UWqqzpOF1S",
   "metadata": {
    "id": "B0UWqqzpOF1S"
   },
   "source": [
    "## Manual Trials\n",
    "\n",
    "Manually trained BERT and RoBERTa on various sample sizes to understand how accuracy scales:\n",
    "- 1000, 5000, 10000 train samples for 5 epochs\n",
    "\n",
    "This section is useful for baseline comparison before running Optuna for automated tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c296d08",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753564680186,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "6c296d08",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "GIMF8cGiV73j",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753564680193,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "GIMF8cGiV73j"
   },
   "outputs": [],
   "source": [
    "# roberta_trainer.train()\n",
    "\n",
    "# # Safely finish run with specific parameters\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f4688",
   "metadata": {
    "id": "580f4688"
   },
   "source": [
    "**Hyperparameters Tuning with Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8X9aALiCIFgT",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1753564680211,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "8X9aALiCIFgT"
   },
   "outputs": [],
   "source": [
    "def build_trainer(model_checkpoint, trial, run_prefix, train_dataset, val_dataset):\n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    num_epochs = trial.suggest_int(\"num_train_epochs\", 2, 5)\n",
    "    n_samples = len(train_dataset)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=5)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    run_name = f\"{run_prefix}-ep{num_epochs}-lr{learning_rate}-bs{batch_size}-samples{n_samples}-run{int(time.time())}-no_preprocess\"\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./results/{run_prefix}/{run_name}\",\n",
    "        disable_tqdm=True,\n",
    "        fp16=True,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=1,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_dir=f\"./logs/{run_prefix}/{run_name}\",\n",
    "        run_name=run_name,\n",
    "        report_to=\"wandb\",\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "RDTlIbcgTdbS",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753564680224,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "RDTlIbcgTdbS"
   },
   "outputs": [],
   "source": [
    "def objective_bert(trial):\n",
    "    trainer = build_trainer(\n",
    "        model_checkpoint=\"bert-base-uncased\",\n",
    "        trial=trial,\n",
    "        run_prefix=\"bert\",\n",
    "        train_dataset=train_dataset_bert,\n",
    "        val_dataset=val_dataset_bert\n",
    "    )\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    return eval_result[\"eval_f1_macro\"]\n",
    "\n",
    "def objective_roberta(trial):\n",
    "    trainer = build_trainer(\n",
    "        model_checkpoint=\"roberta-base\",\n",
    "        trial=trial,\n",
    "        run_prefix=\"roberta\",\n",
    "        train_dataset=train_dataset_roberta,\n",
    "        val_dataset=val_dataset_roberta\n",
    "    )\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    return eval_result[\"eval_f1_macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "FVHz-uRATikZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 270297,
     "status": "ok",
     "timestamp": 1753564950525,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "FVHz-uRATikZ",
    "outputId": "618e232c-508d-4373-a46c-f93233bd78a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:18:00,078] Using an existing study with name 'bert_study' instead of creating a new one.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250726_211801-saohhczy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification/runs/saohhczy' target=\"_blank\">bert-ep3-lr1.8179381685986592e-05-bs16-samples2000-run1753564680-no_preprocess</a></strong> to <a href='https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification' target=\"_blank\">https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification/runs/saohhczy' target=\"_blank\">https://wandb.ai/hillas-tel-aviv-university/tweet-sentiment-classification/runs/saohhczy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5524, 'grad_norm': 6.090435028076172, 'learning_rate': 1.221654449298299e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.503250002861023, 'eval_accuracy': 0.3, 'eval_f1_macro': 0.20947062355060098, 'eval_runtime': 0.7299, 'eval_samples_per_second': 685.05, 'eval_steps_per_second': 43.843, 'epoch': 1.0}\n",
      "{'loss': 1.34, 'grad_norm': 8.667379379272461, 'learning_rate': 6.2052289488167565e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 1.3349297046661377, 'eval_accuracy': 0.39, 'eval_f1_macro': 0.3888128084689583, 'eval_runtime': 0.7105, 'eval_samples_per_second': 703.739, 'eval_steps_per_second': 45.039, 'epoch': 2.0}\n",
      "{'loss': 1.1378, 'grad_norm': 10.126534461975098, 'learning_rate': 1.4543505348789274e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2507128715515137, 'eval_accuracy': 0.464, 'eval_f1_macro': 0.4612105212127416, 'eval_runtime': 0.7065, 'eval_samples_per_second': 707.754, 'eval_steps_per_second': 45.296, 'epoch': 3.0}\n",
      "{'train_runtime': 38.8347, 'train_samples_per_second': 154.501, 'train_steps_per_second': 9.656, 'train_loss': 1.343413533528646, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:18:41,081] Trial 5 finished with value: 0.4612105212127416 and parameters: {'learning_rate': 1.8179381685986592e-05, 'batch_size': 16, 'num_train_epochs': 3}. Best is trial 2 with value: 0.7425764396966665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2507128715515137, 'eval_accuracy': 0.464, 'eval_f1_macro': 0.4612105212127416, 'eval_runtime': 0.7173, 'eval_samples_per_second': 697.034, 'eval_steps_per_second': 44.61, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4788, 'grad_norm': 18.253002166748047, 'learning_rate': 2.48524686309344e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.1820175647735596, 'eval_accuracy': 0.462, 'eval_f1_macro': 0.45481354553139414, 'eval_runtime': 1.3515, 'eval_samples_per_second': 369.968, 'eval_steps_per_second': 46.616, 'epoch': 1.0}\n",
      "{'loss': 1.0547, 'grad_norm': 16.162446975708008, 'learning_rate': 1.8664104928012486e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0282154083251953, 'eval_accuracy': 0.576, 'eval_f1_macro': 0.583580368688682, 'eval_runtime': 1.342, 'eval_samples_per_second': 372.582, 'eval_steps_per_second': 46.945, 'epoch': 2.0}\n",
      "{'loss': 0.6633, 'grad_norm': 15.873087882995605, 'learning_rate': 1.2475741225090575e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1236027479171753, 'eval_accuracy': 0.594, 'eval_f1_macro': 0.605907714087685, 'eval_runtime': 1.3521, 'eval_samples_per_second': 369.807, 'eval_steps_per_second': 46.596, 'epoch': 3.0}\n",
      "{'loss': 0.3488, 'grad_norm': 15.529646873474121, 'learning_rate': 6.31213097698035e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 1.4471008777618408, 'eval_accuracy': 0.584, 'eval_f1_macro': 0.5860953683832338, 'eval_runtime': 1.3445, 'eval_samples_per_second': 371.894, 'eval_steps_per_second': 46.859, 'epoch': 4.0}\n",
      "{'loss': 0.1949, 'grad_norm': 3.2940406799316406, 'learning_rate': 1.2376727405843825e-07, 'epoch': 5.0}\n",
      "{'eval_loss': 1.6186296939849854, 'eval_accuracy': 0.604, 'eval_f1_macro': 0.607330096864638, 'eval_runtime': 1.3431, 'eval_samples_per_second': 372.271, 'eval_steps_per_second': 46.906, 'epoch': 5.0}\n",
      "{'train_runtime': 108.1107, 'train_samples_per_second': 92.498, 'train_steps_per_second': 11.562, 'train_loss': 0.7481017547607421, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:20:33,792] Trial 6 finished with value: 0.607330096864638 and parameters: {'learning_rate': 3.094181851460956e-05, 'batch_size': 8, 'num_train_epochs': 5}. Best is trial 2 with value: 0.7425764396966665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6186296939849854, 'eval_accuracy': 0.604, 'eval_f1_macro': 0.607330096864638, 'eval_runtime': 1.3477, 'eval_samples_per_second': 371.005, 'eval_steps_per_second': 46.747, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5243, 'grad_norm': 4.9427971839904785, 'learning_rate': 1.0323230326940293e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.5067763328552246, 'eval_accuracy': 0.334, 'eval_f1_macro': 0.24482543696808273, 'eval_runtime': 0.7169, 'eval_samples_per_second': 697.425, 'eval_steps_per_second': 44.635, 'epoch': 1.0}\n",
      "{'loss': 1.2815, 'grad_norm': 5.954842567443848, 'learning_rate': 6.9277911743127165e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 1.3025224208831787, 'eval_accuracy': 0.442, 'eval_f1_macro': 0.43521338699660667, 'eval_runtime': 0.7239, 'eval_samples_per_second': 690.716, 'eval_steps_per_second': 44.206, 'epoch': 2.0}\n",
      "{'loss': 1.0781, 'grad_norm': 12.893775939941406, 'learning_rate': 3.5049694478736274e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2630776166915894, 'eval_accuracy': 0.456, 'eval_f1_macro': 0.4449665264885837, 'eval_runtime': 0.7105, 'eval_samples_per_second': 703.751, 'eval_steps_per_second': 45.04, 'epoch': 3.0}\n",
      "{'loss': 0.9508, 'grad_norm': 12.612385749816895, 'learning_rate': 8.214772143453814e-08, 'epoch': 4.0}\n",
      "{'eval_loss': 1.241300344467163, 'eval_accuracy': 0.472, 'eval_f1_macro': 0.48009736685062776, 'eval_runtime': 0.7112, 'eval_samples_per_second': 703.02, 'eval_steps_per_second': 44.993, 'epoch': 4.0}\n",
      "{'train_runtime': 49.1776, 'train_samples_per_second': 162.676, 'train_steps_per_second': 10.167, 'train_loss': 1.2087004089355469, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:21:24,921] Trial 7 finished with value: 0.48009736685062776 and parameters: {'learning_rate': 1.3691286905756356e-05, 'batch_size': 16, 'num_train_epochs': 4}. Best is trial 2 with value: 0.7425764396966665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.241300344467163, 'eval_accuracy': 0.472, 'eval_f1_macro': 0.48009736685062776, 'eval_runtime': 0.7183, 'eval_samples_per_second': 696.047, 'eval_steps_per_second': 44.547, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4537, 'grad_norm': 7.925464630126953, 'learning_rate': 2.5008757740911875e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.2461833953857422, 'eval_accuracy': 0.456, 'eval_f1_macro': 0.4654606425675423, 'eval_runtime': 0.7112, 'eval_samples_per_second': 703.005, 'eval_steps_per_second': 44.992, 'epoch': 1.0}\n",
      "{'loss': 1.0433, 'grad_norm': 8.68944263458252, 'learning_rate': 1.2702861074748887e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.181433081626892, 'eval_accuracy': 0.526, 'eval_f1_macro': 0.5329193026556026, 'eval_runtime': 0.7298, 'eval_samples_per_second': 685.132, 'eval_steps_per_second': 43.848, 'epoch': 2.0}\n",
      "{'loss': 0.7398, 'grad_norm': 11.595009803771973, 'learning_rate': 2.9772330643942706e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1430803537368774, 'eval_accuracy': 0.54, 'eval_f1_macro': 0.5474120900628854, 'eval_runtime': 0.7342, 'eval_samples_per_second': 681.056, 'eval_steps_per_second': 43.588, 'epoch': 3.0}\n",
      "{'train_runtime': 36.7827, 'train_samples_per_second': 163.12, 'train_steps_per_second': 10.195, 'train_loss': 1.078913818359375, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:22:05,761] Trial 8 finished with value: 0.5474120900628854 and parameters: {'learning_rate': 3.721541330492838e-05, 'batch_size': 16, 'num_train_epochs': 3}. Best is trial 2 with value: 0.7425764396966665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1430803537368774, 'eval_accuracy': 0.54, 'eval_f1_macro': 0.5474120900628854, 'eval_runtime': 0.7299, 'eval_samples_per_second': 685.03, 'eval_steps_per_second': 43.842, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5346, 'grad_norm': 6.407988548278809, 'learning_rate': 1.830372914687604e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.5227910280227661, 'eval_accuracy': 0.356, 'eval_f1_macro': 0.32050566067627756, 'eval_runtime': 0.4187, 'eval_samples_per_second': 1194.258, 'eval_steps_per_second': 38.216, 'epoch': 1.0}\n",
      "{'loss': 1.3202, 'grad_norm': 7.393751621246338, 'learning_rate': 9.294862457397989e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 1.282150387763977, 'eval_accuracy': 0.472, 'eval_f1_macro': 0.4747942786821747, 'eval_runtime': 0.4327, 'eval_samples_per_second': 1155.428, 'eval_steps_per_second': 36.974, 'epoch': 2.0}\n",
      "{'loss': 1.1335, 'grad_norm': 11.143248558044434, 'learning_rate': 2.859957679199381e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2531943321228027, 'eval_accuracy': 0.49, 'eval_f1_macro': 0.49332396617628704, 'eval_runtime': 0.424, 'eval_samples_per_second': 1179.199, 'eval_steps_per_second': 37.734, 'epoch': 3.0}\n",
      "{'train_runtime': 22.9775, 'train_samples_per_second': 261.126, 'train_steps_per_second': 8.225, 'train_loss': 1.329422602577815, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:22:30,376] Trial 9 finished with value: 0.49332396617628704 and parameters: {'learning_rate': 2.7026600068434153e-05, 'batch_size': 32, 'num_train_epochs': 3}. Best is trial 2 with value: 0.7425764396966665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2531943321228027, 'eval_accuracy': 0.49, 'eval_f1_macro': 0.49332396617628704, 'eval_runtime': 0.419, 'eval_samples_per_second': 1193.39, 'eval_steps_per_second': 38.188, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "study_bert = optuna.create_study(direction=\"maximize\",\n",
    "                                 pruner=MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
    "                                 study_name=\"bert_study\",\n",
    "                                 storage=\"sqlite:////content/drive/MyDrive/Colab Notebooks/nlp_project/optuna/bert_study.db\",\n",
    "                                 load_if_exists=True)\n",
    "study_bert.optimize(objective_bert, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "tuNyZvQkgY64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317925,
     "status": "ok",
     "timestamp": 1753565268458,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "tuNyZvQkgY64",
    "outputId": "51f6bb4b-7092-461e-a203-a3f9f8360b11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:22:32,970] A new study created in RDB with name: roberta_study\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5704, 'grad_norm': 8.6424560546875, 'learning_rate': 2.9556320201422732e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.485044002532959, 'eval_accuracy': 0.334, 'eval_f1_macro': 0.25037718571490863, 'eval_runtime': 0.4193, 'eval_samples_per_second': 1192.593, 'eval_steps_per_second': 38.163, 'epoch': 1.0}\n",
      "{'loss': 1.3368, 'grad_norm': 14.77864933013916, 'learning_rate': 2.234178534910695e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.3086049556732178, 'eval_accuracy': 0.442, 'eval_f1_macro': 0.45085084395331865, 'eval_runtime': 0.4479, 'eval_samples_per_second': 1116.302, 'eval_steps_per_second': 35.722, 'epoch': 2.0}\n",
      "{'loss': 1.0667, 'grad_norm': 20.166650772094727, 'learning_rate': 1.501088703143123e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2325727939605713, 'eval_accuracy': 0.49, 'eval_f1_macro': 0.47364330361844864, 'eval_runtime': 0.426, 'eval_samples_per_second': 1173.681, 'eval_steps_per_second': 37.558, 'epoch': 3.0}\n",
      "{'loss': 0.8669, 'grad_norm': 27.653209686279297, 'learning_rate': 7.679988713755513e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 1.2053565979003906, 'eval_accuracy': 0.51, 'eval_f1_macro': 0.5198580962212838, 'eval_runtime': 0.4231, 'eval_samples_per_second': 1181.66, 'eval_steps_per_second': 37.813, 'epoch': 4.0}\n",
      "{'loss': 0.7004, 'grad_norm': 22.463930130004883, 'learning_rate': 3.490903960797961e-07, 'epoch': 5.0}\n",
      "{'eval_loss': 1.2176650762557983, 'eval_accuracy': 0.53, 'eval_f1_macro': 0.5400658649582297, 'eval_runtime': 0.4226, 'eval_samples_per_second': 1183.115, 'eval_steps_per_second': 37.86, 'epoch': 5.0}\n",
      "{'train_runtime': 40.2371, 'train_samples_per_second': 248.527, 'train_steps_per_second': 7.829, 'train_loss': 1.1082318623860676, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:23:15,032] Trial 0 finished with value: 0.5400658649582297 and parameters: {'learning_rate': 3.6654491588378584e-05, 'batch_size': 32, 'num_train_epochs': 5}. Best is trial 0 with value: 0.5400658649582297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2176650762557983, 'eval_accuracy': 0.53, 'eval_f1_macro': 0.5400658649582297, 'eval_runtime': 0.4301, 'eval_samples_per_second': 1162.461, 'eval_steps_per_second': 37.199, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.568, 'grad_norm': 6.045679569244385, 'learning_rate': 1.7302165195522193e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.5199531316757202, 'eval_accuracy': 0.306, 'eval_f1_macro': 0.2490897591372871, 'eval_runtime': 0.4244, 'eval_samples_per_second': 1178.005, 'eval_steps_per_second': 37.696, 'epoch': 1.0}\n",
      "{'loss': 1.3646, 'grad_norm': 14.102045059204102, 'learning_rate': 1.3062108902548373e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.4239639043807983, 'eval_accuracy': 0.364, 'eval_f1_macro': 0.3476544559683213, 'eval_runtime': 0.4198, 'eval_samples_per_second': 1191.114, 'eval_steps_per_second': 38.116, 'epoch': 2.0}\n",
      "{'loss': 1.1625, 'grad_norm': 14.79910945892334, 'learning_rate': 8.822052609574555e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 1.3025556802749634, 'eval_accuracy': 0.446, 'eval_f1_macro': 0.4286845544153374, 'eval_runtime': 0.4252, 'eval_samples_per_second': 1175.848, 'eval_steps_per_second': 37.627, 'epoch': 3.0}\n",
      "{'loss': 0.996, 'grad_norm': 27.249895095825195, 'learning_rate': 4.513608311875355e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 1.2420610189437866, 'eval_accuracy': 0.48, 'eval_f1_macro': 0.48633904790598914, 'eval_runtime': 0.4224, 'eval_samples_per_second': 1183.583, 'eval_steps_per_second': 37.875, 'epoch': 4.0}\n",
      "{'loss': 0.888, 'grad_norm': 26.707368850708008, 'learning_rate': 2.7355201890153663e-07, 'epoch': 5.0}\n",
      "{'eval_loss': 1.2509504556655884, 'eval_accuracy': 0.484, 'eval_f1_macro': 0.4913550339262791, 'eval_runtime': 0.416, 'eval_samples_per_second': 1201.878, 'eval_steps_per_second': 38.46, 'epoch': 5.0}\n",
      "{'train_runtime': 39.9682, 'train_samples_per_second': 250.199, 'train_steps_per_second': 7.881, 'train_loss': 1.195832727825831, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:23:56,822] Trial 1 finished with value: 0.4913550339262791 and parameters: {'learning_rate': 2.154222148849601e-05, 'batch_size': 32, 'num_train_epochs': 5}. Best is trial 0 with value: 0.5400658649582297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2509504556655884, 'eval_accuracy': 0.484, 'eval_f1_macro': 0.4913550339262791, 'eval_runtime': 0.4246, 'eval_samples_per_second': 1177.635, 'eval_steps_per_second': 37.684, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5518, 'grad_norm': 3.0561962127685547, 'learning_rate': 3.191401532456544e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.4484853744506836, 'eval_accuracy': 0.364, 'eval_f1_macro': 0.2879114031040758, 'eval_runtime': 0.7262, 'eval_samples_per_second': 688.505, 'eval_steps_per_second': 44.064, 'epoch': 1.0}\n",
      "{'loss': 1.2685, 'grad_norm': 10.72205638885498, 'learning_rate': 1.6146221191875005e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.1982678174972534, 'eval_accuracy': 0.49, 'eval_f1_macro': 0.4989522734721531, 'eval_runtime': 0.714, 'eval_samples_per_second': 700.297, 'eval_steps_per_second': 44.819, 'epoch': 2.0}\n",
      "{'loss': 0.9582, 'grad_norm': 20.852901458740234, 'learning_rate': 5.045694122460939e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1523406505584717, 'eval_accuracy': 0.516, 'eval_f1_macro': 0.5226487464931312, 'eval_runtime': 0.7174, 'eval_samples_per_second': 696.998, 'eval_steps_per_second': 44.608, 'epoch': 3.0}\n",
      "{'train_runtime': 38.0697, 'train_samples_per_second': 157.605, 'train_steps_per_second': 9.85, 'train_loss': 1.2595311279296875, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:24:39,731] Trial 2 finished with value: 0.5226487464931312 and parameters: {'learning_rate': 4.730338239807131e-05, 'batch_size': 16, 'num_train_epochs': 3}. Best is trial 0 with value: 0.5400658649582297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1523406505584717, 'eval_accuracy': 0.516, 'eval_f1_macro': 0.5226487464931312, 'eval_runtime': 0.7353, 'eval_samples_per_second': 680.012, 'eval_steps_per_second': 43.521, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5495, 'grad_norm': 17.7938232421875, 'learning_rate': 1.0211299598711555e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.3879892826080322, 'eval_accuracy': 0.396, 'eval_f1_macro': 0.35512351831415656, 'eval_runtime': 1.3701, 'eval_samples_per_second': 364.948, 'eval_steps_per_second': 45.984, 'epoch': 1.0}\n",
      "{'loss': 1.2589, 'grad_norm': 23.96282386779785, 'learning_rate': 5.176702579863711e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 1.2510786056518555, 'eval_accuracy': 0.462, 'eval_f1_macro': 0.46413962053073315, 'eval_runtime': 1.3581, 'eval_samples_per_second': 368.158, 'eval_steps_per_second': 46.388, 'epoch': 2.0}\n",
      "{'loss': 1.017, 'grad_norm': 24.96974754333496, 'learning_rate': 1.0150397215419041e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2364977598190308, 'eval_accuracy': 0.488, 'eval_f1_macro': 0.49343937357266954, 'eval_runtime': 1.3597, 'eval_samples_per_second': 367.718, 'eval_steps_per_second': 46.332, 'epoch': 3.0}\n",
      "{'train_runtime': 67.0963, 'train_samples_per_second': 89.424, 'train_steps_per_second': 11.178, 'train_loss': 1.2751461995442708, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2364977598190308, 'eval_accuracy': 0.488, 'eval_f1_macro': 0.49343937357266954, 'eval_runtime': 1.3718, 'eval_samples_per_second': 364.476, 'eval_steps_per_second': 45.924, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:25:52,126] Trial 3 finished with value: 0.49343937357266954 and parameters: {'learning_rate': 1.5225595823128561e-05, 'batch_size': 8, 'num_train_epochs': 3}. Best is trial 0 with value: 0.5400658649582297.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5893, 'grad_norm': 3.570788621902466, 'learning_rate': 3.706910363093873e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 1.6233261823654175, 'eval_accuracy': 0.178, 'eval_f1_macro': 0.06044142614601019, 'eval_runtime': 1.3535, 'eval_samples_per_second': 369.4, 'eval_steps_per_second': 46.544, 'epoch': 1.0}\n",
      "{'loss': 1.5847, 'grad_norm': 3.2867724895477295, 'learning_rate': 2.7820325279906117e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 1.595849633216858, 'eval_accuracy': 0.252, 'eval_f1_macro': 0.0805111821086262, 'eval_runtime': 1.3544, 'eval_samples_per_second': 369.175, 'eval_steps_per_second': 46.516, 'epoch': 2.0}\n",
      "{'loss': 1.5775, 'grad_norm': 1.652222990989685, 'learning_rate': 1.8571546928873497e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 1.5942128896713257, 'eval_accuracy': 0.254, 'eval_f1_macro': 0.0810207336523126, 'eval_runtime': 1.3712, 'eval_samples_per_second': 364.639, 'eval_steps_per_second': 45.944, 'epoch': 3.0}\n",
      "{'loss': 1.5801, 'grad_norm': 1.6719151735305786, 'learning_rate': 9.32276857784088e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 1.5940781831741333, 'eval_accuracy': 0.252, 'eval_f1_macro': 0.0805111821086262, 'eval_runtime': 1.3665, 'eval_samples_per_second': 365.911, 'eval_steps_per_second': 46.105, 'epoch': 4.0}\n",
      "{'loss': 1.5766, 'grad_norm': 5.881229877471924, 'learning_rate': 7.399022680826096e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 1.5944355726242065, 'eval_accuracy': 0.252, 'eval_f1_macro': 0.0805111821086262, 'eval_runtime': 1.3606, 'eval_samples_per_second': 367.475, 'eval_steps_per_second': 46.302, 'epoch': 5.0}\n",
      "{'train_runtime': 112.2004, 'train_samples_per_second': 89.126, 'train_steps_per_second': 11.141, 'train_loss': 1.581625732421875, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 21:27:48,309] Trial 4 finished with value: 0.0810207336523126 and parameters: {'learning_rate': 4.624389175516309e-05, 'batch_size': 8, 'num_train_epochs': 5}. Best is trial 0 with value: 0.5400658649582297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5942128896713257, 'eval_accuracy': 0.254, 'eval_f1_macro': 0.0810207336523126, 'eval_runtime': 1.3765, 'eval_samples_per_second': 363.244, 'eval_steps_per_second': 45.769, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "study_roberta = optuna.create_study(direction=\"maximize\",\n",
    "                                    pruner=MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
    "                                    study_name=\"roberta_study\",\n",
    "                                    storage=\"sqlite:////content/drive/MyDrive/Colab Notebooks/nlp_project/optuna/roberta_study.db\",\n",
    "                                    load_if_exists=True)\n",
    "study_roberta.optimize(objective_roberta, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "o6_NmeZoZ8FI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1753568569788,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "o6_NmeZoZ8FI",
    "outputId": "54e9df83-2e5b-4209-8ba2-34a0582f8698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert best trial on subset:\n",
      "{'learning_rate': 3.8115643066555684e-05, 'batch_size': 16, 'num_train_epochs': 2}\n",
      "RoBerta best trial on subset:\n",
      "{'learning_rate': 3.6654491588378584e-05, 'batch_size': 32, 'num_train_epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "best_trial_bert = study_bert.best_trial\n",
    "print('Bert best trial on subset:')\n",
    "print(best_trial_bert.params)\n",
    "best_trial_roberta = study_roberta.best_trial\n",
    "print('RoBerta best trial on subset:')\n",
    "print(best_trial_roberta.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "iAjcXgiz1HDn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418233,
     "status": "ok",
     "timestamp": 1753569143523,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "iAjcXgiz1HDn",
    "outputId": "de851994-2cf0-4bf6-c054-efeabfa96df3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6822, 'grad_norm': 30.361814498901367, 'learning_rate': 1.9094855776443948e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.5002578496932983, 'eval_accuracy': 0.8296471827277514, 'eval_f1_macro': 0.8365850196182407, 'eval_runtime': 5.2425, 'eval_samples_per_second': 724.465, 'eval_steps_per_second': 45.398, 'epoch': 1.0}\n",
      "{'loss': 0.323, 'grad_norm': 6.8882269859313965, 'learning_rate': 4.444109179932649e-08, 'epoch': 2.0}\n",
      "{'eval_loss': 0.432912141084671, 'eval_accuracy': 0.8604528699315429, 'eval_f1_macro': 0.8652364145812331, 'eval_runtime': 5.335, 'eval_samples_per_second': 711.899, 'eval_steps_per_second': 44.611, 'epoch': 2.0}\n",
      "{'train_runtime': 417.0563, 'train_samples_per_second': 197.369, 'train_steps_per_second': 12.339, 'train_loss': 0.5026131966120531, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5146, training_loss=0.5026131966120531, metrics={'train_runtime': 417.0563, 'train_samples_per_second': 197.369, 'train_steps_per_second': 12.339, 'train_loss': 0.5026131966120531, 'epoch': 2.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_trainer_bert = build_trainer(\n",
    "    model_checkpoint=\"bert-base-uncased\",\n",
    "    trial=best_trial_bert,\n",
    "    run_prefix=\"bert_final\",\n",
    "    train_dataset=tokenized_bert_train,\n",
    "    val_dataset=tokenized_bert_val\n",
    ")\n",
    "final_trainer_bert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3z1JVX-11g_o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600880,
     "status": "ok",
     "timestamp": 1753569797258,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "3z1JVX-11g_o",
    "outputId": "a885257c-7e2b-42ca-d224-4f24c77fc972"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-44-2841737310.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8645, 'grad_norm': 42.69869613647461, 'learning_rate': 2.934068161176971e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.7531467080116272, 'eval_accuracy': 0.7374934175882043, 'eval_f1_macro': 0.7268239763823591, 'eval_runtime': 3.0254, 'eval_samples_per_second': 1255.374, 'eval_steps_per_second': 39.334, 'epoch': 1.0}\n",
      "{'loss': 0.5062, 'grad_norm': 34.75946044921875, 'learning_rate': 2.201547940778294e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 0.5646417737007141, 'eval_accuracy': 0.785676671932596, 'eval_f1_macro': 0.7932429470153, 'eval_runtime': 3.0733, 'eval_samples_per_second': 1235.788, 'eval_steps_per_second': 38.72, 'epoch': 2.0}\n",
      "{'loss': 0.3591, 'grad_norm': 18.162437438964844, 'learning_rate': 1.469597331748512e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 0.5656107664108276, 'eval_accuracy': 0.8067403896787783, 'eval_f1_macro': 0.8138838893323017, 'eval_runtime': 3.1066, 'eval_samples_per_second': 1222.552, 'eval_steps_per_second': 38.305, 'epoch': 3.0}\n",
      "{'loss': 0.2692, 'grad_norm': 17.248266220092773, 'learning_rate': 7.365074999809403e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 0.5549362897872925, 'eval_accuracy': 0.8230647709320695, 'eval_f1_macro': 0.8288514526759456, 'eval_runtime': 3.0342, 'eval_samples_per_second': 1251.728, 'eval_steps_per_second': 39.219, 'epoch': 4.0}\n",
      "{'loss': 0.1984, 'grad_norm': 0.987436830997467, 'learning_rate': 3.9872795822634044e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 0.6312575340270996, 'eval_accuracy': 0.8206951026856241, 'eval_f1_macro': 0.8261298552973223, 'eval_runtime': 3.0693, 'eval_samples_per_second': 1237.408, 'eval_steps_per_second': 38.771, 'epoch': 5.0}\n",
      "{'train_runtime': 599.3786, 'train_samples_per_second': 343.331, 'train_steps_per_second': 10.736, 'train_loss': 0.43948856048465423, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6435, training_loss=0.43948856048465423, metrics={'train_runtime': 599.3786, 'train_samples_per_second': 343.331, 'train_steps_per_second': 10.736, 'train_loss': 0.43948856048465423, 'epoch': 5.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_trainer_roberta = build_trainer(\n",
    "    model_checkpoint=\"roberta-base\",\n",
    "    trial=best_trial_roberta,\n",
    "    run_prefix=\"roberta_final\",\n",
    "    train_dataset=tokenized_roberta_train,\n",
    "    val_dataset=tokenized_roberta_val\n",
    ")\n",
    "final_trainer_roberta.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "orC3ee4J3ng4",
   "metadata": {
    "executionInfo": {
     "elapsed": 6795,
     "status": "ok",
     "timestamp": 1753569978457,
     "user": {
      "displayName": "Hilla Scher",
      "userId": "05548285226782472045"
     },
     "user_tz": -180
    },
    "id": "orC3ee4J3ng4"
   },
   "outputs": [],
   "source": [
    "# final_trainer_bert.save_model(\"models/bert_final\")\n",
    "# bert_tokenizer.save_pretrained(\"models/bert_final\")\n",
    "# !cp -r models/bert_final \"/content/drive/MyDrive/Colab Notebooks/nlp_project/models/bert_best_model_no_preprocess\"\n",
    "\n",
    "# final_trainer_roberta.save_model(\"models/roberta_final\")\n",
    "# roberta_tokenizer.save_pretrained(\"models/roberta_final\")\n",
    "# !cp -r models/bert_final \"/content/drive/MyDrive/Colab Notebooks/nlp_project/models/roberta_best_model_no_preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VZe9xCMR8vbj",
   "metadata": {
    "id": "VZe9xCMR8vbj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-hFHWbvH9YBM",
   "metadata": {
    "id": "-hFHWbvH9YBM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/Hillascher5/nlp-tweets-sentiment-analysis/blob/main/Text_Classification_Tweets_Sentiment.ipynb",
     "timestamp": 1753564096575
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01393d8d662e4a02bf98e663181a0253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c650e17245234be7a5d3ed6ed80f616c",
      "max": 3798,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fcbfadd83d114f52ae85cff5113fcdb8",
      "value": 3798
     }
    },
    "021b7b1cd455429f9a394a597d7bb42d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4d498336a3145b4a4aa73fa896b734f",
       "IPY_MODEL_b028b21d6bad410db6cba38dd88b576c",
       "IPY_MODEL_770dfb4419744e0c8b3efae0f3978d60"
      ],
      "layout": "IPY_MODEL_6acee7f7eb284cc3bf62050036746569"
     }
    },
    "22cd9c644bc4455984cffc3ea63d56fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_996a47832e9449248823fc97127afce3",
       "IPY_MODEL_01393d8d662e4a02bf98e663181a0253",
       "IPY_MODEL_84fbe853d81944b699940e78d0f4450c"
      ],
      "layout": "IPY_MODEL_92fe0a22068e4077bac789671b65ac8b"
     }
    },
    "2927695b41b4424fb007825fb2b73bca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28ff50b4dae4c6e85e4915756474036",
      "placeholder": "​",
      "style": "IPY_MODEL_3d3a4e702ce44740a5c5429d61a04ef3",
      "value": "Map: 100%"
     }
    },
    "304c25bb0aec412f92862d42f8f12ec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37aaf2f9b1de473eb376dab3d7a9ed3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d3a4e702ce44740a5c5429d61a04ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fbe6caaa77742d78e5198366626b78f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "603dc04c8c874242bf672876cdad61cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6754ab85e774417280bc6e14fa618a74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6acee7f7eb284cc3bf62050036746569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7542e0c0a355413bb1ab419c7798003e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770dfb4419744e0c8b3efae0f3978d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93247cfcccbb4a2fbe9a74da198a4352",
      "placeholder": "​",
      "style": "IPY_MODEL_603dc04c8c874242bf672876cdad61cd",
      "value": " 41157/41157 [00:03&lt;00:00, 13406.98 examples/s]"
     }
    },
    "7bdeb69ab6294aa8af56486aefc82429": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f74de3720c74099ac30e1664d535d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8329a7608a9b463caefe23dc4f81217a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d5256c4c6a445bc8e3b2d95fa531909",
       "IPY_MODEL_d6643b7caee0485db65270f25d806788",
       "IPY_MODEL_c25775059628480aacb4ceb2ff2047f0"
      ],
      "layout": "IPY_MODEL_7542e0c0a355413bb1ab419c7798003e"
     }
    },
    "83e540139d4a4ca582bcf872a115e960": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84fbe853d81944b699940e78d0f4450c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6754ab85e774417280bc6e14fa618a74",
      "placeholder": "​",
      "style": "IPY_MODEL_37aaf2f9b1de473eb376dab3d7a9ed3e",
      "value": " 3798/3798 [00:00&lt;00:00, 16485.57 examples/s]"
     }
    },
    "8a6cc15567344e7aaaccb719a2a6fb25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d5256c4c6a445bc8e3b2d95fa531909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f584d74ca0ea469bbab2c004a83c8a57",
      "placeholder": "​",
      "style": "IPY_MODEL_fa3cd39c189242558ee65a37e2460d1a",
      "value": "Map: 100%"
     }
    },
    "92fe0a22068e4077bac789671b65ac8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93247cfcccbb4a2fbe9a74da198a4352": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "996a47832e9449248823fc97127afce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bdeb69ab6294aa8af56486aefc82429",
      "placeholder": "​",
      "style": "IPY_MODEL_5fbe6caaa77742d78e5198366626b78f",
      "value": "Map: 100%"
     }
    },
    "9f5350cd17b74d28ab4c3ddd1c2f5b1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0b7181171284283b09914d3553303a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d498336a3145b4a4aa73fa896b734f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f5350cd17b74d28ab4c3ddd1c2f5b1d",
      "placeholder": "​",
      "style": "IPY_MODEL_8a6cc15567344e7aaaccb719a2a6fb25",
      "value": "Map: 100%"
     }
    },
    "ad2f1558713a49f4b458f0b6b1eb1c18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b028b21d6bad410db6cba38dd88b576c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4dd09b398c1462bb967c497c63adc7e",
      "max": 41157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f04b24c43ab245b4a33c93196ab41376",
      "value": 41157
     }
    },
    "b28ff50b4dae4c6e85e4915756474036": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2d101d93d3a4a088f67f817017c0df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2927695b41b4424fb007825fb2b73bca",
       "IPY_MODEL_cea30c0b25d84ac49becf7e530054c1f",
       "IPY_MODEL_daaff61f5e934c7a8fb66e6064dc86ff"
      ],
      "layout": "IPY_MODEL_7f74de3720c74099ac30e1664d535d4f"
     }
    },
    "b37059b31275449e9daf3b481386e37c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4dd09b398c1462bb967c497c63adc7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7866be1713c4ea8adc629e771d138f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf5cd54405444d909c688c9e2c43cc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c25775059628480aacb4ceb2ff2047f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b37059b31275449e9daf3b481386e37c",
      "placeholder": "​",
      "style": "IPY_MODEL_ad2f1558713a49f4b458f0b6b1eb1c18",
      "value": " 41157/41157 [00:02&lt;00:00, 15613.15 examples/s]"
     }
    },
    "c650e17245234be7a5d3ed6ed80f616c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cea30c0b25d84ac49becf7e530054c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf5cd54405444d909c688c9e2c43cc02",
      "max": 3798,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83e540139d4a4ca582bcf872a115e960",
      "value": 3798
     }
    },
    "d4acadb0a1984d3181eabee9f58476ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6643b7caee0485db65270f25d806788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0b7181171284283b09914d3553303a0",
      "max": 41157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4acadb0a1984d3181eabee9f58476ba",
      "value": 41157
     }
    },
    "daaff61f5e934c7a8fb66e6064dc86ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7866be1713c4ea8adc629e771d138f4",
      "placeholder": "​",
      "style": "IPY_MODEL_304c25bb0aec412f92862d42f8f12ec2",
      "value": " 3798/3798 [00:00&lt;00:00, 13188.33 examples/s]"
     }
    },
    "f04b24c43ab245b4a33c93196ab41376": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f584d74ca0ea469bbab2c004a83c8a57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3cd39c189242558ee65a37e2460d1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcbfadd83d114f52ae85cff5113fcdb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
