{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPh2mxLD+4EP11ho+RMLR2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hillascher5/nlp-tweets-sentiment-analysis/blob/main/Evaluate_saved_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Saved Best Models\n",
        "\n",
        "Evaluate models of all types, From Trainer API and manual code models."
      ],
      "metadata": {
        "id": "1Q3qAkioirrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Needed for Google Colab\n",
        "# !pip install --quiet evaluate transformers optuna datasets nltk scikit-learn\n",
        "# !pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "Ms9nSLXui351"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "0Pbbu3fPi1hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed_all(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed_all(42)"
      ],
      "metadata": {
        "id": "lFo_w1F-05BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load test set"
      ],
      "metadata": {
        "id": "35ugAZ8xszgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/nlp_project/Data/Corona_NLP_test_to_evaluate.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "bUNFTiNusbUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping sentiments to unique numeric IDs\n",
        "unique_labels = sorted(df_test[\"Sentiment\"].unique())\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "df_test[\"label\"] = df_test[\"Sentiment\"].map(label2id)"
      ],
      "metadata": {
        "id": "DPDKK2DRrxuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal pre-processing\n",
        "def light_preprocess(text):\n",
        "    return text.strip()                             # Remove unnecessary spaces\n",
        "\n",
        "is_preprocessed = \"minimal_preprocess\"\n",
        "df_test[\"clean_text\"] = df_test[\"OriginalTweet\"].apply(light_preprocess)"
      ],
      "metadata": {
        "id": "4Tb3ls__rcBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to Hugging Face Dataset\n",
        "hf_test = Dataset.from_pandas(df_test[[\"clean_text\", \"label\"]])"
      ],
      "metadata": {
        "id": "GWu23kabuQtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load saved models"
      ],
      "metadata": {
        "id": "b-CzfihzsvnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrw-6thcinlC"
      },
      "outputs": [],
      "source": [
        "model_path_hf = \"/content/drive/MyDrive/Colab Notebooks/nlp_project/models/w_test_split/HF_Trainer/\"\n",
        "bert_model_name_hf = \"bert_best_model_stratify_maxl_256_minimal_preprocess_5000_samples_optuna\"\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(model_path_hf + bert_model_name_hf)\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_path_hf + bert_model_name_hf)\n",
        "\n",
        "roberta_model_name_hf = \"roberta_best_model_stratify_maxl_256_minimal_preprocess_5000_samples_optuna\"\n",
        "roberta_model = AutoModelForSequenceClassification.from_pretrained(model_path_hf + roberta_model_name_hf)\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(model_path_hf + roberta_model_name_hf)\n",
        "\n",
        "deberta_model_name_hf = \"deberta_best_model_stratify_maxl_128_minimal_preprocess_5000_samples_optuna\"\n",
        "deberta_model = AutoModelForSequenceClassification.from_pretrained(model_path_hf + deberta_model_name_hf)\n",
        "deberta_tokenizer = AutoTokenizer.from_pretrained(model_path_hf + deberta_model_name_hf)\n",
        "\n",
        "model_path_manual = \"/content/drive/MyDrive/Colab Notebooks/nlp_project/models/w_test_split/Manual_finetune_min_preproc_5000_samples_opt/\"\n",
        "bert_model_name_manual = \"manual2hf_bert-base-uncased_5000_samples_opt\"\n",
        "bert_model_man = AutoModelForSequenceClassification.from_pretrained(model_path_manual + bert_model_name_manual)\n",
        "bert_tokenizer_man = AutoTokenizer.from_pretrained(model_path_manual + bert_model_name_manual)\n",
        "\n",
        "roberta_model_name_manual = \"manual2hf_roberta-base_5000_samples_opt\"\n",
        "roberta_model_man = AutoModelForSequenceClassification.from_pretrained(model_path_manual + roberta_model_name_manual)\n",
        "roberta_tokenizer_man = AutoTokenizer.from_pretrained(model_path_manual + roberta_model_name_manual)\n",
        "\n",
        "deberta_model_name_manual = \"manual2hf_deberta-base_5000_samples_opt\"\n",
        "deberta_model_man = AutoModelForSequenceClassification.from_pretrained(model_path_manual + deberta_model_name_manual)\n",
        "deberta_tokenizer_man = AutoTokenizer.from_pretrained(model_path_manual + deberta_model_name_manual)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize function\n",
        "def tokenize_function_bert(examples):\n",
        "    return bert_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "def tokenize_function_roberta(examples):\n",
        "    return roberta_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "def tokenize_function_deberta(examples):\n",
        "    return deberta_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "def tokenize_function_bert_man(examples):\n",
        "    return bert_tokenizer_man(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "def tokenize_function_roberta_man(examples):\n",
        "    return roberta_tokenizer_man(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "def tokenize_function_deberta_man(examples):\n",
        "    return deberta_tokenizer_man(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=128)"
      ],
      "metadata": {
        "id": "HgyVQJIttpsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "tokenized_bert_test = hf_test.map(tokenize_function_bert, batched=True)\n",
        "tokenized_bert_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_roberta_test = hf_test.map(tokenize_function_roberta, batched=True)\n",
        "tokenized_roberta_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_deberta_test = hf_test.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_bert_test_man = hf_test.map(tokenize_function_bert_man, batched=True)\n",
        "tokenized_bert_test_man.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_roberta_test_man = hf_test.map(tokenize_function_roberta_man, batched=True)\n",
        "tokenized_roberta_test_man.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_deberta_test_man = hf_test.map(tokenize_function_deberta_man, batched=True)\n",
        "tokenized_deberta_test_man.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "lKX49Rw6uJyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, predictions),\n",
        "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
        "        'precision_macro': precision_score(labels, predictions, average='macro', zero_division=0),\n",
        "        'recall_macro': recall_score(labels, predictions, average='macro'),\n",
        "    }"
      ],
      "metadata": {
        "id": "tHLzvMvzzcEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define trainers\n",
        "bert_trainer_hf = Trainer(model=bert_model, tokenizer=bert_tokenizer, compute_metrics=compute_metrics)\n",
        "roberta_trainer_hf = Trainer(model=roberta_model, tokenizer=roberta_tokenizer, compute_metrics=compute_metrics)\n",
        "deberta_trainer_hf = Trainer(model=deberta_model, tokenizer=deberta_tokenizer, compute_metrics=compute_metrics)\n",
        "\n",
        "bert_trainer_man = Trainer(model=bert_model_man, tokenizer=bert_tokenizer_man, compute_metrics=compute_metrics)\n",
        "roberta_trainer_man = Trainer(model=roberta_model_man, tokenizer=roberta_tokenizer_man, compute_metrics=compute_metrics)\n",
        "deberta_trainer_man = Trainer(model=deberta_model_man, tokenizer=deberta_tokenizer_man, compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "id": "69QfFsxsu2Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "bert_metrics = bert_trainer_hf.evaluate(tokenized_bert_test)\n",
        "print(bert_metrics)\n",
        "\n",
        "roberta_metrics = roberta_trainer_hf.evaluate(tokenized_roberta_test)\n",
        "print(roberta_metrics)\n",
        "\n",
        "deberta_metrics = deberta_trainer_hf.evaluate(tokenized_deberta_test)\n",
        "print(deberta_metrics)\n",
        "\n",
        "bert_metrics_man = bert_trainer_man.evaluate(tokenized_bert_test_man)\n",
        "print(bert_metrics_man)\n",
        "\n",
        "roberta_metrics_man = roberta_trainer_man.evaluate(tokenized_roberta_test_man)\n",
        "print(roberta_metrics_man)\n",
        "\n",
        "deberta_metrics_man = deberta_trainer_man.evaluate(tokenized_deberta_test_man)\n",
        "print(deberta_metrics_man)"
      ],
      "metadata": {
        "id": "FPfk6l15v2nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which metrics to keep\n",
        "keys_to_include = [\n",
        "    'eval_loss',\n",
        "    'eval_accuracy',\n",
        "    'eval_f1_macro',\n",
        "    'eval_precision_macro',\n",
        "    'eval_recall_macro'\n",
        "]\n",
        "\n",
        "# Organize metrics\n",
        "metrics_table = pd.DataFrame([\n",
        "    {\"Model\": \"BERT (HF)\", **{k: v for k, v in bert_metrics.items() if k in keys_to_include}},\n",
        "    {\"Model\": \"RoBERTa (HF)\", **{k: v for k, v in roberta_metrics.items() if k in keys_to_include}},\n",
        "    {\"Model\": \"DeBERTa (HF)\", **{k: v for k, v in deberta_metrics.items() if k in keys_to_include}},\n",
        "    {\"Model\": \"BERT (Manual)\", **{k: v for k, v in bert_metrics_man.items() if k in keys_to_include}},\n",
        "    {\"Model\": \"RoBERTa (Manual)\", **{k: v for k, v in roberta_metrics_man.items() if k in keys_to_include}},\n",
        "    {\"Model\": \"DeBERTa (Manual)\", **{k: v for k, v in deberta_metrics_man.items() if k in keys_to_include}},\n",
        "])\n",
        "\n",
        "# Set index to model name for clarity\n",
        "metrics_table.set_index(\"Model\", inplace=True)\n",
        "\n",
        "# Round values for better readability\n",
        "metrics_table = metrics_table.round(4)\n",
        "\n",
        "from IPython.display import display\n",
        "display(metrics_table)"
      ],
      "metadata": {
        "id": "2nkPL0_oHcKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for classification report\n",
        "bert_preds = bert_trainer_hf.predict(tokenized_bert_test)\n",
        "bert_y_pred = bert_preds.predictions.argmax(axis=-1)\n",
        "bert_y_true = bert_preds.label_ids\n",
        "print('BERT HF Trainer model:')\n",
        "print(classification_report(bert_y_true, bert_y_pred, digits=4))\n",
        "\n",
        "roberta_preds = roberta_trainer_hf.predict(tokenized_roberta_test)\n",
        "roberta_y_pred = roberta_preds.predictions.argmax(axis=-1)\n",
        "roberta_y_true = roberta_preds.label_ids\n",
        "print('RoBERTa HF Trainer model:')\n",
        "print(classification_report(roberta_y_true, roberta_y_pred, digits=4))\n",
        "\n",
        "deberta_preds = deberta_trainer_hf.predict(tokenized_deberta_test)\n",
        "deberta_y_pred = deberta_preds.predictions.argmax(axis=-1)\n",
        "deberta_y_true = deberta_preds.label_ids\n",
        "print('DeBERTa HF Trainer model:')\n",
        "print(classification_report(deberta_y_true, deberta_y_pred, digits=4))\n",
        "\n",
        "bert_preds_man = bert_trainer_man.predict(tokenized_bert_test_man)\n",
        "bert_y_pred_man = bert_preds_man.predictions.argmax(axis=-1)\n",
        "bert_y_true_man = bert_preds_man.label_ids\n",
        "print('BERT manual code model:')\n",
        "print(classification_report(bert_y_true_man, bert_y_pred_man, digits=4))\n",
        "\n",
        "roberta_preds_man = roberta_trainer_man.predict(tokenized_roberta_test_man)\n",
        "roberta_y_pred_man = roberta_preds_man.predictions.argmax(axis=-1)\n",
        "roberta_y_true_man = roberta_preds_man.label_ids\n",
        "print('RoBERTA manual code model:')\n",
        "print(classification_report(roberta_y_true_man, roberta_y_pred_man, digits=4))\n",
        "\n",
        "deberta_preds_man = deberta_trainer_man.predict(tokenized_deberta_test_man)\n",
        "deberta_y_pred_man = deberta_preds_man.predictions.argmax(axis=-1)\n",
        "deberta_y_true_man = deberta_preds_man.label_ids\n",
        "print('DeBERTA manual code model:')\n",
        "print(classification_report(deberta_y_true_man, deberta_y_pred_man, digits=4))\n"
      ],
      "metadata": {
        "id": "HXl1r-lwv8QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Javascript\n",
        "\n",
        "# def disconnect_runtime():\n",
        "#     display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "# disconnect_runtime()"
      ],
      "metadata": {
        "id": "kDtJ0GWh0I74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}