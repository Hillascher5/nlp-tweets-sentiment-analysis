{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPtBZqWnZIfi1u+GwufOQP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hillascher5/nlp-tweets-sentiment-analysis/blob/main/DeBerta_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try another model for the task"
      ],
      "metadata": {
        "id": "QuMksGtXPH5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5n6iVnKO8GJ"
      },
      "outputs": [],
      "source": [
        "# # Needed for Google Colab\n",
        "# !pip install --quiet evaluate transformers optuna datasets nltk scikit-learn\n",
        "# !pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.exc import GeocoderTimedOut\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from optuna.pruners import MedianPruner\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "import nltk\n",
        "import evaluate\n",
        "import transformers\n",
        "import torch\n",
        "import optuna\n",
        "import wandb\n",
        "wandb.login()\n",
        "# API key - 0cbd7fe3cffd71df993b30edb4fa0db94f114413\n",
        "\n",
        "num_train_samples = 5000\n",
        "os.environ[\"WANDB_PROJECT\"] = f\"tweet-sentiment-classification_split_to_test_maxl_128_deberta_{num_train_samples}_samples_optuna\"\n",
        "os.environ[\"WANDB_INIT_TIMEOUT\"] = \"180\"\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "aqmJFcuDPS8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed_all(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed_all(42)"
      ],
      "metadata": {
        "id": "YO86ZTlVvUkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp_project/Data/Corona_NLP_train.csv', encoding='latin1')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp_project/Data/Corona_NLP_test.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "TFMan1IiPYUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge and shuffle for better stratified splits\n",
        "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
        "df_full = df_full.sample(frac=1.0, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uvgzCWKxPbj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try without pre-processing\n",
        "is_preprocessed = \"no_preprocess\"\n",
        "df_full[\"clean_text\"] = df_full[\"OriginalTweet\"]"
      ],
      "metadata": {
        "id": "-kKoOBvqPd58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping sentiments to unique numeric IDs\n",
        "unique_labels = sorted(df_full[\"Sentiment\"].unique())\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "df_full[\"label\"] = df_full[\"Sentiment\"].map(label2id)"
      ],
      "metadata": {
        "id": "ENXyMQPsPjVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified split: 70% train, 15% val, 15% test\n",
        "train_val_df, test_df = train_test_split(df_full, test_size=0.15, stratify=df_full[\"label\"], random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1765, stratify=train_val_df[\"label\"], random_state=42)\n",
        "\n",
        "# Confirm sizes\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(val_df))\n",
        "print(\"Test size:\", len(test_df))"
      ],
      "metadata": {
        "id": "qt_6tFsKPpwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset_df, _ = train_test_split(\n",
        "    train_df[[\"clean_text\", \"label\"]],\n",
        "    train_size=num_train_samples,\n",
        "    stratify=train_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_subset_df, _ = train_test_split(\n",
        "    val_df[[\"clean_text\", \"label\"]],\n",
        "    train_size=500,\n",
        "    stratify=val_df[\"label\"],\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "tsc8XVWiPuFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose pretrained models\n",
        "deberta_model_name = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "sentiment_labels = df_full['Sentiment'].unique()\n",
        "n_labels = len(sentiment_labels)\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "deberta_tokenizer = AutoTokenizer.from_pretrained(deberta_model_name)\n",
        "deberta_model = AutoModelForSequenceClassification.from_pretrained(deberta_model_name, num_labels=n_labels)"
      ],
      "metadata": {
        "id": "MshYxTH3Pge7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize function\n",
        "def tokenize_function_deberta(examples):\n",
        "    return deberta_tokenizer(examples[\"clean_text\"], truncation=True, padding='max_length', max_length=128)"
      ],
      "metadata": {
        "id": "kAf36TYSPv6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to Hugging Face Dataset\n",
        "hf_subset_train = Dataset.from_pandas(train_subset_df)\n",
        "hf_subset_val = Dataset.from_pandas(val_subset_df)\n",
        "\n",
        "hf_train = Dataset.from_pandas(train_df[[\"clean_text\", \"label\"]])\n",
        "hf_val = Dataset.from_pandas(val_df[[\"clean_text\", \"label\"]])\n",
        "hf_test = Dataset.from_pandas(test_df[[\"clean_text\", \"label\"]])"
      ],
      "metadata": {
        "id": "QvtxTOhlPyob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize subsets\n",
        "# Tokenize for DeBERTa\n",
        "tokenized_deberta_train_sub = hf_subset_train.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_train_sub.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_deberta_val_sub = hf_subset_val.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_val_sub.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "_0yGNMG8P1OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize full dataset\n",
        "# Tokenize for BERT\n",
        "tokenized_deberta_train = hf_train.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_deberta_val = hf_val.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "tokenized_deberta_test = hf_test.map(tokenize_function_deberta, batched=True)\n",
        "tokenized_deberta_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "23Qs5lyvP3Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision_macro\": precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall_macro\":    recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "hnFwcxffP5ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_trainer(model_checkpoint, trial, run_prefix, train_dataset, val_dataset):\n",
        "    # Sample hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    num_epochs = trial.suggest_int(\"num_train_epochs\", 2, 5)\n",
        "    n_samples = len(train_dataset)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=5)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    run_name = f\"{run_prefix}-ep{num_epochs}-lr{learning_rate}-bs{batch_size}-samples{n_samples}-run{int(time.time())}-{is_preprocessed}\"\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"./results/{run_prefix}/{run_name}\",\n",
        "        disable_tqdm=True,\n",
        "        fp16=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=num_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=0.01,\n",
        "        label_smoothing_factor=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        save_total_limit=1,\n",
        "        logging_strategy=\"epoch\",\n",
        "        logging_dir=f\"./logs/{run_prefix}/{run_name}\",\n",
        "        run_name=run_name,\n",
        "        report_to=\"wandb\",\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "FgJWGgSkP7oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_deberta(trial):\n",
        "    trainer = build_trainer(\n",
        "        model_checkpoint=\"microsoft/deberta-v3-base\",\n",
        "        trial=trial,\n",
        "        run_prefix=\"deberta\",\n",
        "        train_dataset=tokenized_deberta_train_sub,\n",
        "        val_dataset=tokenized_deberta_val_sub\n",
        "    )\n",
        "    trainer.train()\n",
        "    eval_result = trainer.evaluate()\n",
        "    wandb.finish()\n",
        "    return eval_result[\"eval_f1_macro\"]"
      ],
      "metadata": {
        "id": "wcW-klOTP_LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_deberta = optuna.create_study(direction=\"maximize\",\n",
        "                                 pruner=MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
        "                                 study_name=f\"deberta_study_stratify_{is_preprocessed}\",\n",
        "                                 storage=f\"sqlite:////content/drive/MyDrive/Colab Notebooks/nlp_project/optuna/deberta_study_stratify_maxl_128_{is_preprocessed}_{num_train_samples}_samples_optuna.db\",\n",
        "                                 load_if_exists=True)\n",
        "study_deberta.optimize(objective_deberta, n_trials=5)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "lIn83SWhQBbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial_deberta = study_deberta.best_trial\n",
        "print('DeBerta best trial on subset:')\n",
        "print(best_trial_deberta.params)"
      ],
      "metadata": {
        "id": "9dpxPyrFQDvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_deberta = best_trial_deberta.params\n",
        "run_name_deberta = f\"deberta_final_stratify_{is_preprocessed}-ep{best_params_deberta['num_train_epochs']}-lr{best_params_deberta['learning_rate']:.1e}-bs{best_params_deberta['batch_size']}\"\n",
        "wandb.init(project=f\"tweet-sentiment-classification_split_to_test_maxl_128_deberta_{num_train_samples}_samples_optuna\", name=run_name_deberta, reinit=True)\n",
        "\n",
        "final_trainer_deberta = build_trainer(\n",
        "    model_checkpoint=\"microsoft/deberta-v3-base\",\n",
        "    trial=best_trial_deberta,\n",
        "    run_prefix=f\"deberta_final_stratify_{is_preprocessed}\",\n",
        "    train_dataset=tokenized_deberta_train,\n",
        "    val_dataset=tokenized_deberta_val\n",
        ")\n",
        "final_trainer_deberta.train()\n",
        "final_trainer_deberta.evaluate(tokenized_deberta_test)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "t0s91u4cQJjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_trainer_deberta.save_model(f\"models/w_test_split/deberta_final_stratify_{is_preprocessed}_{num_train_samples}_samples_optuna\")\n",
        "deberta_tokenizer.save_pretrained(f\"models/w_test_split/deberta_final_stratify_{is_preprocessed}_{num_train_samples}_samples_optuna\")\n",
        "!cp -r models/w_test_split/deberta_final_stratify_{is_preprocessed}_{num_train_samples}_samples_optuna \"/content/drive/MyDrive/Colab Notebooks/nlp_project/models/w_test_split/deberta_best_model_stratify_maxl_128_{is_preprocessed}_{num_train_samples}_samples_optuna\""
      ],
      "metadata": {
        "id": "gHUvBjW0QOkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C45Nn00jZqd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}